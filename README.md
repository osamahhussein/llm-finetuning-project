# LLM Fine-Tuning Project

This repository contains my final project for the Generative Artificial Intelligence course.  
The project focuses on fine-tuning the TinyLlama language model using a custom question–answer dataset.

## Project Objective
The main goal of this project is to understand how large language models (LLMs) can be adapted to specific tasks using fine-tuning techniques such as LoRA (Low-Rank Adaptation).

## Dataset
A small custom dataset was created in instruction–response format.  
Each example follows this structure:

- Instruction: A question about generative AI  
- Response: A clear and concise answer  

The dataset includes topics such as:
- What is generative AI  
- Differences between generative and discriminative models  
- Applications of generative AI  
- Overfitting and generalization  
- Language models  

## Model and Tools
- Base model: TinyLlama  
- Fine-tuning method: LoRA  
- Environment: Google Colab  
- Libraries: Transformers, PEFT, PyTorch  

## Notebook
The full training process is available in the notebook:
- `Untitled3.ipynb`

It includes:
- Loading the model  
- Preparing the dataset  
- Tokenization  
- Training configuration  
- Fine-tuning  
- Testing the fine-tuned model  

## Learning Outcomes
Through this project, I learned:
- How instruction datasets are structured  
- How LoRA fine-tuning works  
- How to use HuggingFace Transformers for training  
- How to manage an ML project using GitHub  

## Author
Osamah Hussein  
Firat University  
Generative AI Course – Final Project


